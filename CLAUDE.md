# CoderingsTool Project Context  

## Project Overview

CoderingsTool is a sophisticated text analysis pipeline for processing survey responses from SPSS files. The system performs text preprocessing, quality filtering, embedding generation, clustering, and hierarchical labeling of open-ended survey responses to identify themes and patterns.

### âœ… Working Pipeline (Steps 1-8) 
The core pipeline successfully processes data through 5 complete stages:

1. **âœ… Data Loading** - SPSS (.sav) files â†’ ResponseModel objects
2. **âœ… Preprocessing** - Text normalization, spell checking, finalization  
3. **âœ… Segmentation** - Quality filtering, descriptive code generation
4. **âœ… Embeddings** - OpenAI-based code and description embeddings
5. **âœ… Initial clustering** - Two-phase HDBSCAN clustering with LLM-based merging producing micro clusters

Work to be done/TODO:
6. **ğŸ“Œ Hierarchical clustering** - node level 1,2,3 clustering by LLM microclusters. level 1= themes, level 2= topics and level 3= keywords
   - â˜ Design MapReduce pipeline structure with LangChain
   - â˜ Implement micro-cluster extraction with representative selection
   - â˜ Create Map phase for batch summarization
   - â˜ Create Reduce phase for hierarchical summarization
   - â˜ Implement final hierarchy generation with constraints
7. **ğŸ“Œ Summarization** - LLM produced summary of each theme
   - â˜ Implement theme summarization using LLM
8. **ğŸ“Œ Visualization** - dendrogram and wordclouds based on c-tf-idf and mmr
   - â˜ Implement visualization: dendrograms for hierarchical structure
   - â˜ Implement visualization: wordclouds based on C-TF-IDF
   - â˜ Implement MMR (Maximal Marginal Relevance) for keyword selection


## Project Structure

```
CoderingsTool/
â”œâ”€â”€ data/                          # Input data files and chache 
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py               # Package initialization
â”‚   â”œâ”€â”€ app.py                    # Streamlit web application
â”‚   â”œâ”€â”€ cache_manager.py          # Cache management system
â”‚   â”œâ”€â”€ config.py                 # **UNIFIED** configuration (all configs merged)
â”‚   â”œâ”€â”€ models.py                 # Pydantic data models
â”‚   â”œâ”€â”€ pipeline.py               # Main processing pipeline
â”‚   â”œâ”€â”€ prompts.py                # LLM prompts
â”‚   â”œâ”€â”€ ui_text.py                # UI text constants
â”‚   â””â”€â”€ utils/                    # **MOVED** from modules/utils/
â”‚       â”œâ”€â”€ analyze_labels.py
â”‚       â”œâ”€â”€ clusterMerger.py      
â”‚       â”œâ”€â”€ cluster_quality.py     
â”‚       â”œâ”€â”€ clusterer.py
â”‚       â”œâ”€â”€ csvHandler.py
â”‚       â”œâ”€â”€ data_io.py
â”‚       â”œâ”€â”€ embedder.py
â”‚       â”œâ”€â”€ preprocessor.py
â”‚       â”œâ”€â”€ qualityFilter.py
â”‚       â”œâ”€â”€ segmentDescriber.py
â”‚       â”œâ”€â”€ spellChecker.py
â”‚       â”œâ”€â”€ textFinalizer.py
â”‚       â””â”€â”€ textNormalizer.py
â””â”€â”€ requirements.txt
â””â”€â”€ environment.yml

```

## Key Architecture Patterns (Unchanged)

### Data Models (Pydantic)
- **Hierarchical inheritance**: ResponseModel â†’ PreprocessModel â†’ DescriptiveModel â†’ EmbeddingsModel â†’ ClusterModel â†’ LabelModel
- **Type safety** with numpy array support
- **Model conversion** methods for pipeline progression

### Async Processing Patterns
- **Consistent async/await** for I/O operations
- **Batch processing** with concurrency limits for API calls
- **Instructor library** integration for structured LLM responses

### Unified Configuration System  
- **Single config.py file** with all configuration classes:
  - `CacheConfig` - Cache management settings
  - `ProcessingConfig` - Processing parameters that affect cache validity
  - `ClusteringConfig` - Automatic clustering parameters
  - `CacheDatabase` - SQLite database operations class
- **Environment variable** support for API keys and paths
- **Default instances** ready to use: `DEFAULT_CACHE_CONFIG`, `DEFAULT_PROCESSING_CONFIG`, `DEFAULT_CLUSTERING_CONFIG`

### Caching System
- **SQLite-backed** cache with CSV data storage
- **Configuration-aware** cache invalidation
- **Step-by-step** pipeline caching for efficient reruns

### Dependencies & Integrations
- **OpenAI API**: Embeddings and LLM completions via instructor
- **HDBSCAN + UMAP**: Clustering algorithms
- **Spacy**: NLP processing
- **Hunspell**: Multi-language spell checking (Dutch/English)
- **SQLite**: Caching backend
- **Pydantic**: Data validation and models

### Running the Pipeline
```bash
cd src
python pipeline.py
```

## Development Workflow

### Collaboration Rules
- **Claude develops**: Claude develops, refines and updates code, which will be added, committed and pushed to the GitHub repo
- **User tests**: The user will pull the updates and test code in Spyder, locally
- **Iterative refinement**: Based on test results, Claude will update and improve the code

