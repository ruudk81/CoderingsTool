# CoderingsTool Project Context  

## Project Overview

CoderingsTool is a sophisticated text analysis pipeline for processing survey responses from SPSS files. The system performs text preprocessing, quality filtering, embedding generation, clustering, and hierarchical labeling of open-ended survey responses to identify themes and patterns.

### âœ… Working Pipeline (Steps 1-6) 
The core pipeline successfully processes data through 6 complete stages:

1. **âœ… Data Loading** - SPSS (.sav) files â†’ ResponseModel objects
2. **âœ… Preprocessing** - Text normalization, spell checking, finalization  
3. **âœ… Segmentation** - Quality filtering, descriptive code generation
4. **âœ… Embeddings** - OpenAI-based code and description embeddings
5. **âœ… Clustering** - Two-phase HDBSCAN clustering with LLM-based merging
6. **âœ… Hierarchical Labeling** - 3-phase LLM-based Themeâ†’Topicâ†’Keyword hierarchy

### ðŸ”§ Refinement Needed
- **Step 6**: Refine code, investigate opportunities to improve performance in terms of speed, investigate opportunities to improve the quality of the prompts

## Project Structure

```
CoderingsTool/
â”œâ”€â”€ data/                          # Input data files
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py               # Package initialization
â”‚   â”œâ”€â”€ app.py                    # Streamlit web application
â”‚   â”œâ”€â”€ cache_manager.py          # Cache management system
â”‚   â”œâ”€â”€ config.py                 # **UNIFIED** configuration (all configs merged)
â”‚   â”œâ”€â”€ models.py                 # Pydantic data models
â”‚   â”œâ”€â”€ pipeline.py               # Main processing pipeline
â”‚   â”œâ”€â”€ prompts.py                # LLM prompts
â”‚   â”œâ”€â”€ ui_text.py                # UI text constants
â”‚   â””â”€â”€ utils/                    # **MOVED** from modules/utils/
â”‚       â”œâ”€â”€ analyze_labels.py
â”‚       â”œâ”€â”€ clusterMerger.py      
â”‚       â”œâ”€â”€ cluster_quality.py     
â”‚       â”œâ”€â”€ clusterer.py
â”‚       â”œâ”€â”€ csvHandler.py
â”‚       â”œâ”€â”€ data_io.py
â”‚       â”œâ”€â”€ embedder.py
â”‚       â”œâ”€â”€ labeller.py            
â”‚       â”œâ”€â”€ preprocessor.py
â”‚       â”œâ”€â”€ qualityFilter.py
â”‚       â”œâ”€â”€ segmentDescriber.py
â”‚       â”œâ”€â”€ spellChecker.py
â”‚       â”œâ”€â”€ textFinalizer.py
â”‚       â””â”€â”€ textNormalizer.py
â””â”€â”€ requirements.txt
```

## Key Architecture Patterns (Unchanged)

### Data Models (Pydantic)
- **Hierarchical inheritance**: ResponseModel â†’ PreprocessModel â†’ DescriptiveModel â†’ EmbeddingsModel â†’ ClusterModel â†’ LabelModel
- **Type safety** with numpy array support
- **Model conversion** methods for pipeline progression

### Async Processing Patterns
- **Consistent async/await** for I/O operations
- **Batch processing** with concurrency limits for API calls
- **Instructor library** integration for structured LLM responses

### Unified Configuration System  
- **Single config.py file** with all configuration classes:
  - `CacheConfig` - Cache management settings
  - `ProcessingConfig` - Processing parameters that affect cache validity
  - `ClusteringConfig` - Automatic clustering parameters
  - `CacheDatabase` - SQLite database operations class
- **Environment variable** support for API keys and paths
- **Default instances** ready to use: `DEFAULT_CACHE_CONFIG`, `DEFAULT_PROCESSING_CONFIG`, `DEFAULT_CLUSTERING_CONFIG`

### Caching System
- **SQLite-backed** cache with CSV data storage
- **Configuration-aware** cache invalidation
- **Step-by-step** pipeline caching for efficient reruns

### Dependencies & Integrations
- **OpenAI API**: Embeddings and LLM completions via instructor
- **HDBSCAN + UMAP**: Clustering algorithms
- **Spacy**: NLP processing
- **Hunspell**: Multi-language spell checking (Dutch/English)
- **SQLite**: Caching backend
- **Pydantic**: Data validation and models

### Running the Pipeline
```bash
cd src
python pipeline.py
```

### Configuration Usage
All configuration is now centralized:
```python
from config import DEFAULT_CACHE_CONFIG, DEFAULT_PROCESSING_CONFIG, DEFAULT_CLUSTERING_CONFIG
from config import CacheConfig, ProcessingConfig, ClusteringConfig, CacheDatabase
```
